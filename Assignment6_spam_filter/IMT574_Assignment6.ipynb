{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psy = pd.read_csv(\"./data/YouTube-Spam-Collection-v1/Youtube01-Psy.csv\")\n",
    "perry = pd.read_csv(\"./data/YouTube-Spam-Collection-v1/Youtube02-KatyPerry.csv\")\n",
    "lmf = pd.read_csv(\"./data/YouTube-Spam-Collection-v1/Youtube03-LMFAO.csv\")\n",
    "emin = pd.read_csv(\"./data/YouTube-Spam-Collection-v1/Youtube04-Eminem.csv\")\n",
    "shak = pd.read_csv(\"./data/YouTube-Spam-Collection-v1/Youtube05-Shakira.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine all datasets into one, and drop unnecessary features\n",
    "nbdf = pd.concat([shak, perry, psy, lmf, emin]).reset_index()\n",
    "nbdf = nbdf.iloc[:,4:]\n",
    "\n",
    "## Clean all comments of punctuation\n",
    "nbdf['CONTENT'] = nbdf['CONTENT'].str.replace('\\W',' ')\n",
    "nbdf['CONTENT'] = nbdf['CONTENT'].str.lower()\n",
    "nbdf['CONTENT'] = nbdf['CONTENT'].str.split()\n",
    "\n",
    "## Run through each line and gather unique words within the document\n",
    "dictionary = []\n",
    "for line in nbdf['CONTENT']:\n",
    "    for word in line:\n",
    "        dictionary.append(word)\n",
    "dictionary = list(set(dictionary))\n",
    "\n",
    "## Dictionary assigning a wordcount to each unique word in the doc\n",
    "word_count_per_line = {unique_word: [0] * len(nbdf['CONTENT']) for unique_word in dictionary}\n",
    "for index, line in enumerate(nbdf['CONTENT']):\n",
    "    for word in line:\n",
    "        word_count_per_line[word][index] +=1\n",
    "word_counts = pd.DataFrame(word_count_per_line)\n",
    "\n",
    "## Combine the words count and total dataframe sets into one; drop commonly-used English words that mean little\n",
    "clean = pd.concat([nbdf, word_counts], axis = 1)\n",
    "clean = clean.drop(['i','and','the','but','a','in','of','be','that','have','it','for','on','with', 'this', 'is', 'to'], axis = 1)\n",
    "\n",
    "\n",
    "## Split based on seam made during concatenation; grab shak observations for testing set. THIS IS NOT RANDOM.\n",
    "train = clean.iloc[len(shak):,:]\n",
    "test = clean.iloc[:len(shak),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splt further, dividing X and y\n",
    "Xtrain = train.drop(['CONTENT','CLASS'], axis = 1)\n",
    "ytrain = train['CLASS']\n",
    "\n",
    "Xtest = test.drop(['CONTENT','CLASS'], axis = 1)\n",
    "ytest = test[['CLASS']]\n",
    "\n",
    "# Instantiate and train model\n",
    "mnb = MultinomialNB().fit(Xtrain, ytrain)\n",
    "y_hat = mnb.predict(Xtest)\n",
    "\n",
    "# Test model (it did OK)\n",
    "acc = accuracy_score(ytest, y_hat)\n",
    "print(acc, \"\\n\")\n",
    "conf = confusion_matrix(ytest, y_hat)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Play with the results\n",
    "test['predictions'] = gnb.predict(Xtest)\n",
    "incorrect1 = test[test['predictions'] != test['CLASS']][['CONTENT','CLASS','predictions']]\n",
    "results1 = test[['CONTENT','CLASS','predictions']]\n",
    "results1.columns = ['NBComments','NBClass','NBPredictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Focus on creating own version of NB ###############\n",
    "\n",
    "## Drop unimportant attributes\n",
    "df = pd.concat([perry, psy, lmf, emin], axis = 0)\n",
    "df = df.reset_index()\n",
    "df = df.iloc[:,4:]\n",
    "\n",
    "# Clean\n",
    "df['CONTENT'] = df['CONTENT'].str.replace('\\W',' ')\n",
    "df['CONTENT'] = df['CONTENT'].str.lower()\n",
    "df['CONTENT'] = df['CONTENT'].str.split()\n",
    "\n",
    "## Split comments into singular unique words\n",
    "dictionary = []\n",
    "for line in df['CONTENT']:\n",
    "    for word in line:\n",
    "        dictionary.append(word)\n",
    "dictionary = list(set(dictionary))\n",
    "\n",
    "## Convert list of unique words into a dictionary with key: unique word, value: count\n",
    "word_count_per_line = {unique_word: [0] * len(df['CONTENT']) for unique_word in dictionary}\n",
    "for index, line in enumerate(df['CONTENT']):\n",
    "    for word in line:\n",
    "        word_count_per_line[word][index] +=1\n",
    "word_counts = pd.DataFrame(word_count_per_line)\n",
    "clean_training = pd.concat([df, word_counts], axis = 1)\n",
    "\n",
    "## remove grouping of words that are influential for mean nothing (i, and, but)\n",
    "dictionary = [x for x in dictionary if x not in ['i','and','the','but','a','in','of','be','that','have','it','for','on','with', 'this', 'is', 'to']]\n",
    "clean_training = clean_training.drop(['i','and','the','but','a','in','of','be','that','have','it','for','on','with', 'this', 'is', 'to'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup\n",
    "spam = clean_training[clean_training['CLASS'] == 1]\n",
    "ham = clean_training[clean_training['CLASS'] == 0]\n",
    "\n",
    "## P(y == 1) & P(y == 0)\n",
    "pspam = len(spam)/len(clean_training)\n",
    "pham = len(ham)/len(clean_training)\n",
    "\n",
    "# Count words per comment in spam and ham\n",
    "n_words_in_spam = spam['CONTENT'].apply(len)\n",
    "n_words_in_ham = ham['CONTENT'].apply(len)\n",
    "\n",
    "# Count total number of words for spam and ham\n",
    "n_spam = n_words_in_spam.sum()\n",
    "n_ham = n_words_in_ham.sum()\n",
    "\n",
    "# Total number of unique words\n",
    "n_dict = len(dictionary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "## Initialization\n",
    "params_spam = {unique_word: 0 for unique_word in dictionary}\n",
    "params_ham = {unique_word: 0 for unique_word in dictionary}\n",
    "\n",
    "## Calculation -> P(word|y == 1) & P(word|y == 0)\n",
    "for word in dictionary:\n",
    "    nword_in_spam = spam[word].sum()\n",
    "    # Occurance of the word in spam / total words in spam\n",
    "    pword_in_spam = (nword_in_spam + alpha)/(n_spam + alpha * n_dict)\n",
    "    params_spam[word] = pword_in_spam\n",
    "\n",
    "    nword_in_ham = ham[word].sum()\n",
    "    # Occurance of the wod in ham / total words in ham\n",
    "    pword_in_ham = (nword_in_ham + alpha)/(n_ham + alpha * n_dict)\n",
    "    params_ham[word] = pword_in_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    p_spam_given_message = pspam\n",
    "    p_ham_given_message = pham\n",
    "\n",
    "    for word in message:\n",
    "        print(word)\n",
    "        if word in params_spam:\n",
    "            p_spam_given_message *= params_spam[word]\n",
    "        if word in params_ham:\n",
    "            p_ham_given_message *= params_ham[word]\n",
    "    \n",
    "    print('P(spam|message): ', p_spam_given_message)\n",
    "    print('P(ham|message): ', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: ham')\n",
    "        return(0)\n",
    "    else:\n",
    "        print('Label: spam')\n",
    "        return(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the function\n",
    "test_set = shak.iloc[:,3:]\n",
    "classify(test_set['CONTENT'].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test(message):\n",
    "    message = re.sub('\\W',' ', message)\n",
    "    message = message.lower().split()\n",
    "\n",
    "    p_ham_given_message = pham\n",
    "    p_spam_given_message = pspam\n",
    "\n",
    "    for word in message:\n",
    "        if word in params_spam:\n",
    "            p_spam_given_message *= params_spam[word]\n",
    "        if word in params_ham:\n",
    "            p_ham_given_message *= params_ham[word]\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Running the function en masse, adding the resultant column as part of the dataframe\n",
    "test_set['predictions'] = test_set['CONTENT'].apply(classify_test)\n",
    "\n",
    "# Check accuracy\n",
    "correct = 0\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['CLASS'] == row['predictions']:\n",
    "        correct += 1\n",
    "accuracy = correct/len(test_set)\n",
    "print('Correct: ', correct)\n",
    "print('Incorrect: ', len(test_set) - correct)\n",
    "print('Accuracy: ', accuracy)\n",
    "\n",
    "results2 = test_set[['CONTENT', 'CLASS','predictions']]\n",
    "results2.columns = ['HMComments','HMClass','HMPredictions']\n",
    "incorrect2 = test_set[test_set['predictions'] != test_set['CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisonSet = pd.concat((results1, results2), axis = 1)\n",
    "comparisonSet.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "maxVal = 0\n",
    "for pair in params_ham:\n",
    "    value = params_ham[pair]\n",
    "    if value > maxVal:\n",
    "        maxVal = value\n",
    "        print(maxVal)\n",
    "\n",
    "#maxVal = 0\n",
    "#for pair in params_spam:\n",
    "#    value = params_spam[pair]\n",
    "#    if value > maxVal:\n",
    "#        maxVal = value\n",
    "#        print(maxVal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(params_spam.keys())\n",
    "vals = list(params_spam.values())\n",
    "\n",
    "# out\n",
    "keys[vals.index(0.019946091644204852)]\n",
    "# to\n",
    "keys[vals.index(0.01567834681042228)]\n",
    "# youtube\n",
    "keys[vals.index(0.009478885893980233)]\n",
    "# channel\n",
    "keys[vals.index(0.007412398921832884)]\n",
    "# amp\n",
    "#keys[vals.index(0.005207865672981952)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(params_ham.keys())\n",
    "vals = list(params_ham.values())\n",
    "\n",
    "# song\n",
    "keys[vals.index(0.01379014989293362)]\n",
    "\n",
    "# to\n",
    "keys[vals.index(0.010706638115631691)]\n",
    "\n",
    "# like\n",
    "keys[vals.index(0.006338329764453961)]\n",
    "\n",
    "# to\n",
    "#keys[vals.index(0.0107048043161771)]\n",
    "\n",
    "# like\n",
    "#keys[vals.index(0.006337244155176843)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}